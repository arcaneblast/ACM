{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ThreeStepSearchPipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ealhomsi/ACM/blob/master/ThreeStepSearchPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVUzyPNdDnfW",
        "colab_type": "text"
      },
      "source": [
        "Install NVIDIA cuda toolkit and other dependencies. We'll run a simple Numba cuda kernel to ensure everything works correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tk35E2mDaP_",
        "colab_type": "code",
        "outputId": "c7e9d71f-dd4a-4b34-e8a2-4ca13bcef366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "!apt-get install nvidia-cuda-toolkit\n",
        "!pip3 install numba\n",
        "!pip3 install opencv-python\n",
        "!pip3 install wurlitzer\n",
        "!pip3 install imutils\n",
        "\n",
        "import os\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/lib/nvidia-cuda-toolkit/libdevice\"\n",
        "os.environ['NUMBAPRO_NVVM'] = \"/usr/lib/x86_64-linux-gnu/libnvvm.so.3.2.0\"\n",
        "\n",
        "from numba import cuda, float32, types\n",
        "import numba\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "@cuda.jit\n",
        "def hello(data):\n",
        "    data[cuda.blockIdx.x, cuda.threadIdx.x] = cuda.blockIdx.x * 1024 + cuda.threadIdx.x\n",
        "\n",
        "numBlocks = 5\n",
        "threadsPerBlock = 10\n",
        "\n",
        "data = np.ones((numBlocks, threadsPerBlock), dtype=np.uint8)\n",
        "\n",
        "hello[numBlocks, threadsPerBlock](data)\n",
        "\n",
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "nvidia-cuda-toolkit is already the newest version (9.1.85-3ubuntu1).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " nvidia-cuda-toolkit : Depends: nvidia-cuda-dev (= 9.1.85-3ubuntu1) but it is not going to be installed\n",
            "E: Unmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (0.40.1)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba) (0.30.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from numba) (1.17.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.7.28)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.17.4)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.6/dist-packages (0.5.3)\n",
            "[[0 1 2 3 4 5 6 7 8 9]\n",
            " [0 1 2 3 4 5 6 7 8 9]\n",
            " [0 1 2 3 4 5 6 7 8 9]\n",
            " [0 1 2 3 4 5 6 7 8 9]\n",
            " [0 1 2 3 4 5 6 7 8 9]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ptO74ZCD0K1",
        "colab_type": "text"
      },
      "source": [
        "We'll define the cuda kernel for performing thhe three step search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc3mpkO0EWRT",
        "colab_type": "code",
        "outputId": "ec3955ea-5ec9-47f7-ac8f-8535a20614dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "DRIVE_PATH = '/content/gdrive/My Drive/BlockMatching/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr4aG9kSDg0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cmath\n",
        "\n",
        "\n",
        "@cuda.jit(device=True)\n",
        "def block_is_oob(frame, anchor, block_size):\n",
        "    return (anchor[0] < 0) or (anchor[1] < 0) or (anchor[0] >= frame.shape[0] - block_size[0]) or (anchor[1] >= frame.shape[1] - block_size[1])\n",
        "    \n",
        "\n",
        "@cuda.jit(device=True)\n",
        "def device_gpu_round(x):\n",
        "    # Numba bugs out if we use round() built-in in python\n",
        "    val = float(int(x))\n",
        "    if abs(x - val) > 0.5:\n",
        "        return float(int(x + 0.5 * abs(x) / x))\n",
        "    \n",
        "    return val\n",
        "\n",
        "\n",
        "@cuda.jit(device=True)\n",
        "def search_direction(step_size, z):\n",
        "    # Use an 8th root of unity to create the rotation towards to the search\n",
        "    # direction\n",
        "    sqrt_2 = cmath.sqrt(2)\n",
        "    scalar = sqrt_2 if z % 2 == 1 else complex(1)\n",
        "\n",
        "    angle = 2 * 3.14159265359 / 8 * z\n",
        "    root = cmath.cos(angle) + cmath.sin(angle) * 1j\n",
        "    rotation = step_size * scalar * root\n",
        "\n",
        "    # Resolve any truncation errors from using floating points\n",
        "    # by rounding the real and imaginary parts\n",
        "    return device_gpu_round(rotation.real) + device_gpu_round(rotation.imag) * 1j\n",
        "\n",
        "\n",
        "@cuda.jit(device=True)\n",
        "def device_seq_mae(frame, next_frame, anchor, next_anchor, block_size):\n",
        "    output = 0\n",
        "\n",
        "    for i in range(block_size[0]):\n",
        "        for j in range(block_size[1]):\n",
        "            error = (\n",
        "                float(frame[anchor[0] + i, anchor[1] + j]) - \n",
        "                float(next_frame[next_anchor[0] + i, next_anchor[1] + j])\n",
        "            )\n",
        "\n",
        "            if error < 0:\n",
        "                error *= -1\n",
        "            \n",
        "            output += error\n",
        "    \n",
        "    return output / (block_size[0] * block_size[1])\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def tss_estimation(frame, next_frame, block_size, image_block_layout, motion_vectors):\n",
        "    errors = cuda.shared.array(shape=(10, 10, 8), dtype=numba.float32)\n",
        "    anchor = cuda.local.array(shape=(2,), dtype=numba.int32)\n",
        "    next_anchor = cuda.local.array(shape=(2,), dtype=numba.int32)\n",
        "\n",
        "    image_block_x = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
        "    image_block_y = cuda.blockIdx.y * cuda.blockDim.y + cuda.threadIdx.y\n",
        "\n",
        "    if image_block_x > image_block_layout[0] or image_block_y > image_block_layout[1]:\n",
        "        return\n",
        "    \n",
        "    if cuda.threadIdx.z == 0:\n",
        "        motion_vectors[image_block_x, image_block_y, 0] = 0\n",
        "        motion_vectors[image_block_x, image_block_y, 1] = 0\n",
        "    \n",
        "    anchor[0] = image_block_x * block_size[0]\n",
        "    anchor[1] = image_block_y * block_size[1]\n",
        "\n",
        "    if device_seq_mae(frame, next_frame, anchor, anchor, block_size) < 5.5:\n",
        "        return\n",
        "\n",
        "    step_size = 4\n",
        "\n",
        "    while step_size >= 1:\n",
        "        # The direction to search in depends on threadIdx.z\n",
        "        rotation = search_direction(step_size, cuda.threadIdx.z)\n",
        "        next_anchor[0] = anchor[0] + rotation.real\n",
        "        next_anchor[1] = anchor[1] + rotation.imag\n",
        "\n",
        "        if block_is_oob(frame, next_anchor, block_size):\n",
        "            errors[cuda.threadIdx.x, cuda.threadIdx.y, cuda.threadIdx.z] = np.inf\n",
        "        else:\n",
        "            errors[cuda.threadIdx.x, cuda.threadIdx.y, cuda.threadIdx.z] = device_seq_mae(frame, next_frame, anchor, next_anchor, block_size)\n",
        "\n",
        "        cuda.syncthreads()\n",
        "\n",
        "        if cuda.threadIdx.z == 0:\n",
        "            # Get MSE of current location\n",
        "            no_motion_mse = device_seq_mae(frame, next_frame, anchor, anchor, block_size)\n",
        "\n",
        "            argmin_mse = 0\n",
        "            min_mse = np.inf\n",
        "\n",
        "            for z in range(8):\n",
        "                if errors[cuda.threadIdx.x, cuda.threadIdx.y, z] < min_mse:\n",
        "                    min_mse = errors[cuda.threadIdx.x, cuda.threadIdx.y, z]\n",
        "                    argmin_mse = z\n",
        "\n",
        "            if no_motion_mse > min_mse:\n",
        "                # If the best point is not the center of the search space then we shift the \n",
        "                # motion vectors and anchor for the next step by that direction\n",
        "                direction = search_direction(step_size, argmin_mse)\n",
        "                motion_vectors[image_block_x, image_block_y, 0] += direction.real\n",
        "                motion_vectors[image_block_x, image_block_y, 1] += direction.imag\n",
        "\n",
        "                anchor[0] += direction.real\n",
        "                anchor[1] += direction.imag\n",
        "        \n",
        "        cuda.syncthreads()\n",
        "\n",
        "        step_size //= 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj73_EwaEOV4",
        "colab_type": "text"
      },
      "source": [
        "Define a function for drawing a motion vector in the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEsLbdQ2D8LU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_motion_vector(frame, motion_vectors, block):\n",
        "    # Centroid of the block in pixels\n",
        "    origin = block_size * block + (block_size / 2)\n",
        "    point_at = origin + motion_vectors[block[0], block[1]]\n",
        "\n",
        "    origin = tuple(np.flip(origin.astype(np.int32), axis=0))\n",
        "    point_at = tuple(np.flip(point_at.astype(np.int32), axis=0))\n",
        "\n",
        "    cv2.arrowedLine(frame, origin, point_at, (0, 0, 0), 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5jcG25mEUqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "video_shapes = np.array([[360, 640], [720, 1280]])\n",
        "\n",
        "def find_nearest(frame_shape):\n",
        "    distances = np.abs(np.sum(video_shapes ** 2 - frame_shape ** 2, axis=1))\n",
        "    closest = distances.argmin()\n",
        "    return video_shapes[closest]\n",
        "\n",
        "\n",
        "def pad_frame(frame, h, w):\n",
        "    padded_frame = np.zeros((h, w, frame.shape[2]), dtype=np.uint8)\n",
        "    h_pad = (h - frame.shape[0]) // 2\n",
        "    w_pad = (w - frame.shape[1]) // 2\n",
        "\n",
        "    padded_frame[h_pad:h-h_pad, w_pad:w-w_pad, :] = frame\n",
        "    return padded_frame\n",
        "\n",
        "\n",
        "def frame_pair_generator(initial_frame, video_capture, read_flag, h, w):\n",
        "    initial_frame = pad_frame(initial_frame, h, w)\n",
        "\n",
        "    while read_flag:\n",
        "        read_flag, frame = video_capture.read()\n",
        "\n",
        "        if read_flag:\n",
        "            padded_frame = pad_frame(frame, h, w)\n",
        "            yield (initial_frame, padded_frame)\n",
        "            initial_frame = padded_frame\n",
        "    \n",
        "    yield (initial_frame, None)\n",
        "\n",
        "\n",
        "def load_video(video_file):\n",
        "    video_path = os.path.join(DRIVE_PATH, video_file)\n",
        "    capture = cv2.VideoCapture(video_path)\n",
        "\n",
        "    fps = capture.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    print(\"FPS: {0}\".format(fps))\n",
        "    print(\"Frame count: {0}\".format(frame_count))\n",
        "    \n",
        "    read_flag, frame = capture.read()\n",
        "    h, w = find_nearest(np.array(frame.shape[1:3]))\n",
        "\n",
        "    return frame_pair_generator(frame, capture, read_flag, h, w), fps, frame_count, h, w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nouYNwuaEh4m",
        "colab_type": "text"
      },
      "source": [
        "We'll now process the video using the three step search algorithm using a pipeline to avoid consuming too much memory.\n",
        "\n",
        "1. We'll load a pair of frames from the video (x_1, x_2)\n",
        "2. We'll run three step search on the grayscale images to calculate the motion vectors\n",
        "3. We'll draw the motion vectors and write the output frame to an output video using ffmpeg to encode the output video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYUY2yzyGIFm",
        "colab_type": "code",
        "outputId": "5e339910-c4dc-45be-cfa4-14deceb52957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "import tqdm\n",
        "import subprocess as sp\n",
        "\n",
        "INPUT_VIDEO = ('baseball_720p', '.mp4')\n",
        "\n",
        "gen, fps, frames, h, w = load_video(''.join(INPUT_VIDEO))\n",
        "\n",
        "block_size = np.array([8, 8])\n",
        "image_block_layout = (h // block_size[0], w // block_size[1])\n",
        "gpu_block_layout = (10, 10)\n",
        "\n",
        "# 8 threads per image block, 12*8 image blocks per gpu block\n",
        "thread_layout = (*gpu_block_layout, 8)\n",
        "\n",
        "gpu_block_num = tuple((l + (b - 1)) // b for l, b in zip(image_block_layout, gpu_block_layout))\n",
        "\n",
        "# Initialize some memory for the motion vectors\n",
        "motion_vectors = np.zeros((*image_block_layout, 2), dtype=np.int8)\n",
        "\n",
        "cmd = [\n",
        "    '/usr/bin/ffmpeg',\n",
        "    '-y',\n",
        "    '-f', 'image2pipe',\n",
        "    '-i', '-',\n",
        "    '-framerate', '%.02f' % fps,\n",
        "    '-vcodec', 'libx264',\n",
        "    '-s', '%dx%d' % (w, h),\n",
        "    '-pix_fmt', 'yuv420p',\n",
        "    '-preset', 'medium',\n",
        "    '-an',\n",
        "    os.path.join(DRIVE_PATH, '%s_out.mp4' % INPUT_VIDEO[0])\n",
        "]\n",
        "\n",
        "\n",
        "# Open FFMpeg with a pipe to stdin to pass each frame as a jpeg image and encode an avi video\n",
        "proc = sp.Popen(cmd, stdin=sp.PIPE, stdout=sp.DEVNULL)\n",
        "\n",
        "for color_frame, color_next_frame in tqdm.tqdm(gen, 'Processing frames', total=frames):\n",
        "    # Grayscale transformation\n",
        "    frame = np.sum(color_frame / color_frame.shape[2], axis=2).astype(np.uint8)\n",
        "\n",
        "    if color_next_frame is not None:\n",
        "        next_frame = np.sum(color_next_frame / color_frame.shape[2], axis=2).astype(np.uint8)\n",
        "        \n",
        "        # Perform motion estimation on the device with three step search\n",
        "        tss_estimation[gpu_block_num, gpu_block_layout](frame, next_frame, block_size, np.array(image_block_layout), motion_vectors)\n",
        "\n",
        "        non_zero_vectors = np.logical_not(np.all(np.equal(motion_vectors, 0), axis=2))\n",
        "        where = np.where(non_zero_vectors)\n",
        "\n",
        "        # Draw all non zero motion vectors\n",
        "        for block_x, block_y in zip(*where):\n",
        "            draw_motion_vector(color_frame, motion_vectors, np.array([block_x, block_y], dtype=np.int32))\n",
        "\n",
        "    success, jpeg = cv2.imencode('.jpg', color_frame)\n",
        "    proc.stdin.write(jpeg.tobytes())\n",
        "\n",
        "\n",
        "proc.stdin.close()\n",
        "proc.wait()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rProcessing frames:   0%|          | 0/1049 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "FPS: 29.97002997002997\n",
            "Frame count: 1049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Processing frames: 100%|██████████| 1049/1049 [01:29<00:00, 11.72it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}